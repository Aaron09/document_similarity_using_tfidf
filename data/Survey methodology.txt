For the Statistics Canada publication, see Survey Methodology.
A field of applied statistics of human research surveys, survey methodology studies the sampling of individual units from a population and the associated survey data collection techniques, such as questionnaire construction and methods for improving the number and accuracy of responses to surveys. Survey methodology includes instruments or procedures that ask one or more questions that may, or may not, be answered.[1]
Statistical surveys are undertaken with a view towards making statistical inferences about the population being studied, and this depends strongly on the survey questions used. Polls about public opinion, public health surveys, market research surveys, government surveys and censuses are all examples of quantitative research that use contemporary survey methodology to answer questions about a population. Although censuses do not include a "sample," they do include other aspects of survey methodology, like questionnaires, interviewers, and nonresponse follow-up techniques. Surveys provide important information for all kinds of public information and research fields, e.g., marketing research, psychology, health professionals and sociology.[2]



Contents


1 Overview
2 Selecting samples
3 Modes of data collection
4 Research designs

4.1 Cross-sectional studies
4.2 Successive independent samples studies
4.3 Longitudinal studies


5 Questionnaires

5.1 Questionnaires as tools
5.2 Reliability and validity of self-report measures
5.3 Composing a questionnaire
5.4 Guidelines for the effective wording of questions
5.5 Order of questions


6 Nonresponse reduction
7 Interviewer effects
8 See also
9 References
10 Further reading



Overview[edit]
A single survey is made of at least a sample (or full population in the case of a census), a method of data collection (e.g., a questionnaire) and individual questions or items that become data that can be analyzed statistically. A single survey may focus on different types of topics such as preferences (e.g., for a presidential candidate), opinions (e.g., should abortion be legal?), behavior (smoking and alcohol use), or factual information (e.g., income), depending on its purpose. Since survey research is almost always based on a sample of the population, the success of the research is dependent on the representativeness of the sample with respect to a target population of interest to the researcher. That target population can range from the general population of a given country to specific groups of people within that country, to a membership list of a professional organization, or list of students enrolled in a school system (see also sampling (statistics) and survey sampling). The persons replying to a survey are called respondents, and depending on the questions asked their answers may represent themselves as individuals, their households, employers, or other organization they represent.
Survey methodology as a scientific field seeks to identify principles about the sample design, data collection instruments, statistical adjustment of data, and data processing, and final data analysis that can create systematic and random survey errors. Survey errors are sometimes analyzed in connection with survey cost. Cost constraints are sometimes framed as improving quality within cost constraints, or alternatively, reducing costs for a fixed level of quality. Survey methodology is both a scientific field and a profession, meaning that some professionals in the field focus on survey errors empirically and others design surveys to reduce them. For survey designers, the task involves making a large set of decisions about thousands of individual features of a survey in order to improve it.[3]
The most important methodological challenges of a survey methodologist include making decisions on how to:[3]

Identify and select potential sample members.
Contact sampled individuals and collect data from those who are hard to reach (or reluctant to respond)
Evaluate and test questions.
Select the mode for posing questions and collecting responses.
Train and supervise interviewers (if they are involved).
Check data files for accuracy and internal consistency.
Adjust survey estimates to correct for identified errors.

Selecting samples[edit]
Main article: Survey sampling
The sample is chosen from the sampling frame, which consists of a list of all members of the population of interest.[4] The goal of a survey is not to describe the sample, but the larger population. This generalizing ability is dependent on the representativeness of the sample, as stated above. Each member of the population is termed an element. There are frequent difficulties one encounters while choosing a representative sample. One common error that results is selection bias. Selection bias results when the procedures used to select a sample result in over representation or under representation of some significant aspect of the population. For instance, if the population of interest consists of 75% females, and 25% males, and the sample consists of 40% females and 60% males, females are under represented while males are overrepresented. In order to minimize selection biases, stratified random sampling is often used. This is when the population is divided into sub-populations called strata, and random samples are drawn from each of the strata, or elements are drawn for the sample on a proportional basis.
Modes of data collection[edit]
Main article: Survey data collection
There are several ways of administering a survey. The choice between administration modes is influenced by several factors, including

costs,
coverage of the target population,
flexibility of asking questions,
respondents' willingness to participate and
response accuracy.

Different methods create mode effects that change how respondents answer, and different methods have different advantages. The most common modes of administration can be summarized as:[5]

Telephone
Mail (post)
Online surveys
Personal in-home surveys
Personal mall or street intercept survey
Hybrids of the above.

Research designs[edit]
There are several different designs, or overall structures, that can be used in survey research. The three general types are cross-sectional, successive independent samples, and longitudinal studies.[4]
Cross-sectional studies[edit]
In cross-sectional studies, a sample (or samples) is drawn from the relevant population and studied once.[4] A cross-sectional study describes characteristics of that population at one time, but cannot give any insight as to the causes of population characteristics because it is a predictive, correlational design.
Successive independent samples studies[edit]
A successive independent samples design draws multiple random samples from a population at one or more times.[4] This design can study changes within a population, but not changes within individuals because the same individuals are not surveyed more than once. Such studies cannot, therefore, identify the causes of change over time necessarily. For successive independent samples designs to be effective, the samples must be drawn from the same population, and must be equally representative of it. If the samples are not comparable, the changes between samples may be due to demographic characteristics rather than time. In addition, the questions must be asked in the same way so that responses can be compared directly.
Longitudinal studies[edit]
Longitudinal studies take measure of the same random sample at multiple time points.[4] Unlike with a successive independent samples design, this design measures the differences in individual participants’ responses over time. This means that a researcher can potentially assess the reasons for response changes by assessing the differences in respondents’ experiences. Longitudinal studies are the easiest way to assess the effect of a naturally occurring event, such as divorce that cannot be tested experimentally. However, longitudinal studies are both expensive and difficult to do. It’s harder to find a sample that will commit to a months- or years-long study than a 15-minute interview, and participants frequently leave the study before the final assessment. This attrition of participants is not random, so samples can become less representative with successive assessments. To account for this, a researcher can compare the respondents who left the survey to those that did not, to see if they are statistically different populations. Respondents may also try to be self-consistent in spite of changes to survey answers.
Questionnaires[edit]
Questionnaires are the most commonly used tool in survey research. However, the results of a particular survey are worthless if the questionnaire is written inadequately.[4] Questionnaires should produce valid and reliable demographic variable measures and should yield valid and reliable individual disparities that self-report scales generate.[4]
Questionnaires as tools[edit]
A variable category that is often measured in survey research are demographic variables, which are used to depict the characteristics of the people surveyed in the sample.[4] Demographic variables include such measures as ethnicity, socioeconomic status, race, and age.[4] Surveys often assess the preferences and attitudes of individuals, and many employ self-report scales to measure people’s opinions and judgements about different items presented on a scale.[4] Self-report scales are also used to examine the disparities among people on scale items.[4] These self-report scales, which are usually presented in questionnaire form, are one of the most used instruments in psychology, and thus it is important that the measures be constructed carefully, while also being reliable and valid.[4]
Reliability and validity of self-report measures[edit]
Reliable measures of self-report are defined by their consistency.[4] Thus, a reliable self-report measure produces consistent results every time it is executed.[4] A test’s reliability can be measured a few ways.[4] First, one can calculate a test-retest reliability.[4] A test-retest reliability entails conducting the same questionnaire to a large sample at two different times.[4] For the questionnaire to be considered reliable, people in the sample do not have to score identically on each test, but rather their position in the score distribution should be similar for both the test and the retest.[4] Self-report measures will generally be more reliable when they have many items measuring a construct.[4] Furthermore, measurements will be more reliable when the factor being measured has greater variability among the individuals in the sample that are being tested.[4] Finally, there will be greater reliability when instructions for the completion of the questionnaire are clear and when there are limited distractions in the testing environment.[4] Contrastingly, a questionnaire is valid if what it measures is what it had originally planned to measure.[4] Construct validity of a measure is the degree to which it measures the theoretical construct that it was originally supposed to measure.[4]
It is important to note that there is evidence to suggest that self-report measures tend to be less accurate and reliable than alternative methods of assessing data (e.g. observational studies; for an example, see [6].
Composing a questionnaire[edit]
Six steps can be employed to construct a questionnaire that will produce reliable and valid results.[4] First, one must decide what kind of information should be collected.[4] Second, one must decide how to conduct the questionnaire.[4] Thirdly, one must construct a first draft of the questionnaire.[4] Fourth, the questionnaire should be revised.[4] Next, the questionnaire should be pretested.[4] Finally, the questionnaire should be edited and the procedures for its use should be specified.[4]
Guidelines for the effective wording of questions[edit]
The way that a question is phrased can have a large impact on how a research participant will answer the question.[4] Thus, survey researchers must be conscious of their wording when writing survey questions.[4] It is important for researchers to keep in mind that different individuals, cultures, and subcultures can interpret certain words and phrases differently from one another.[4] There are two different types of questions that survey researchers use when writing a questionnaire: free response questions and closed questions.[4] Free response questions are open-ended, whereas closed questions are usually multiple choice.[4] Free response questions are beneficial because they allow the responder greater flexibility, but they are also very difficult to record and score, requiring extensive coding.[4] Contrastingly, closed questions can be scored and coded much easier, but they diminish expressivity and spontaneity of the responder.[4] In general, the vocabulary of the questions should be very simple and direct, and most should be less than twenty words.[4] Each question should be edited for "readability" and should avoid leading or loaded questions.[4] Finally, if multiple items are being used to measure one construct, the wording of some of the items should be worded in the opposite direction to evade response bias.[4]
A respondent's answer to an open-ended question can be coded into a response scale afterwards,[5] or analysed using more qualitative methods.
Order of questions[edit]
Survey researchers should carefully construct the order of questions in a questionnaire.[4] For questionnaires that are self-administered, the most interesting questions should be at the beginning of the questionnaire to catch the respondent’s attention, while demographic questions should be near the end.[4] Contrastingly, if a survey is being administered over the telephone or in person, demographic questions should be administered at the beginning of the interview to boost the respondent’s confidence.[4] Another reason to be mindful of question order may cause a survey response effect in which one question may affect how people respond to subsequent questions as a result of priming.
Nonresponse reduction[edit]
The following ways have been recommended for reducing nonresponse[7] in telephone and face-to-face surveys:[8]

Advance letter. A short letter is sent in advance to inform the sampled respondents about the upcoming survey. The style of the letter should be personalized but not overdone. First, it announces that a phone call will be made, or an interviewer wants to make an appointment to do the survey face-to-face. Second, the research topic will be described. Last, it allows both an expression of the surveyor's appreciation of cooperation and an opening to ask questions on the survey.
Training. The interviewers are thoroughly trained in how to ask respondents questions, how to work with computers and making schedules for callbacks to respondents who were not reached.
Short introduction. The interviewer should always start with a short introduction about him or herself. She/he should give her name, the institute she is working for, the length of the interview and goal of the interview. Also it can be useful to make clear that you are not selling anything: this has been shown to lead to a slightly higher responding rate.[9]
Respondent-friendly survey questionnaire. The questions asked must be clear, non-offensive and easy to respond to for the subjects under study.

Brevity is also often cited as increasing response rate. A 1996 literature review found mixed evidence to support this claim for both written and verbal surveys, concluding that other factors may often be more important.[10] A 2010 study looking at 100,000 online surveys found response rate dropped by about 3% at 10 questions and about 6% at 20 questions, with drop-off slowing (for example, only 10% reduction at 40 questions).[11] Other studies showed that quality of response degraded toward the end of long surveys.[12]
Interviewer effects[edit]
Survey methodologists have devoted much effort to determining the extent to which interviewee responses are affected by physical characteristics of the interviewer. Main interviewer traits that have been demonstrated to influence survey responses are race,[13] gender,[14] and relative body weight (BMI).[15] These interviewer effects are particularly operant when questions are related to the interviewer trait. Hence, race of interviewer has been shown to affect responses to measures regarding racial attitudes,[16] interviewer sex responses to questions involving gender issues,[17] and interviewer BMI answers to eating and dieting-related questions.[18] While interviewer effects have been investigated mainly for face-to-face surveys, they have also been shown to exist for interview modes with no visual contact, such as telephone surveys and in video-enhanced web surveys. The explanation typically provided for interviewer effects is social desirability bias: survey participants may attempt to project a positive self-image in an effort to conform to the norms they attribute to the interviewer asking questions. Interviewer effects are one example survey response effects.
See also[edit]


Statistics portal



Data Documentation Initiative
Enterprise feedback management (EFM)
Likert scale
Official statistics
Paid survey
Quantitative marketing research
Questionnaire construction
Ratio estimator
Social research
Total survey error

References[edit]


^ George Beam. The Problem with Survey Research (2012) New Brunswick, NJ: Transaction, p. xv.
^ "WhatIsASurvey.info". WhatIsASurvey.info. Retrieved 2013-10-03. 
^ a b Groves, R.M.; Fowler, F. J.; Couper, M.P.; Lepkowski, J.M.; Singer, E.; Tourangeau, R. (2009). Survey Methodology. New Jersey: John Wiley & Sons. ISBN 978-1-118-21134-2. 
^ a b c d e f g h i j k l m n o p q r s t u v w x y z aa ab ac ad ae af ag ah ai aj ak al am an ao ap aq Shaughnessy, J.; Zechmeister, E.; Jeanne, Z. (2011). Research methods in psychology (9th ed.). New York, NY: McGraw Hill. pp. 161–175. 
^ a b Mellenbergh, G.J. (2008). Chapter 9: Surveys. In H.J. Adèr & G.J. Mellenbergh (Eds.) (with contributions by D.J. Hand), Advising on Research Methods: A consultant's companion (pp. 183–209). Huizen, The Netherlands: Johannes van Kessel Publishing.
^ Prince et al., 2008)
^ Lynn, P. (2008) "The problem of non-response", chapter 3, 35-55, in International Handbook of Survey Methodology (ed.s Edith de Leeuw, Joop Hox & Don A. Dillman). Erlbaum. ISBN 0-8058-5753-2
^ Dillman, D.A. (1978) Mail and telephone surveys: The total design method. Wiley. ISBN 0-471-21555-4
^ De Leeuw, E.D. (2001). "I am not selling anything: Experiments in telephone introductions". Kwantitatieve Methoden, 22, 41–48.
^ Bogen, Karen (1996). "THE EFFECT OF QUESTIONNAIRE LENGTH ON RESPONSE RATES -- A REVIEW OF THE LITERATURE" (PDF). Proceedings of the Section on Survey Research Methods. American Statistical Association: 1020–1025. Retrieved 2013-03-19. 
^ "Does Adding One More Question Impact Survey Completion Rate?". 2010-12-10. Retrieved 2017-11-08. 
^ "Respondent engagement and survey length: the long and the short of it". research. April 7, 2010. Retrieved 2013-10-03. 
^ Hill, M.E (2002). "Race of the interviewer and perception of skin color: Evidence from the multi-city study of urban inequality". American Sociological Review. 67 (1): 99–108. doi:10.2307/3088935. JSTOR 3088935. 
^ Flores-Macias, F.; Lawson, C. (2008). "Effects of interviewer gender on survey responses: Findings from a household survey in Mexico". International Journal of Public Opinion Research. 20 (1): 100–110. doi:10.1093/ijpor/edn007. 
^ Eisinga, R.; Te Grotenhuis, M.; Larsen, J.K.; Pelzer, B.; Van Strien, T. (2011). "BMI of interviewer effects". International Journal of Public Opinion Research. 23 (4): 530–543. doi:10.1093/ijpor/edr026. 
^ Anderson, B.A.; Silver, B.D.; Abramson, P.R. (1988). "The effects of the race of the interviewer on race-related attitudes of black respondents in SRC/CPS national election studies". Public Opinion Quarterly. 52 (3): 1–28. doi:10.1086/269108. 
^ Kane, E.W.; MacAulay, L.J. (1993). "Interviewer gender and gender attitudes". Public Opinion Quarterly. 57 (1): 1–28. doi:10.1086/269352. 
^ Eisinga, R.; Te Grotenhuis, M.; Larsen, J.K.; Pelzer, B. (2011). "Interviewer BMI effects on under- and over-reporting of restrained eating. Evidence from a national Dutch face-to-face survey and a postal follow-up". International Journal of Public Health. 57 (3): 643–647. doi:10.1007/s00038-011-0323-z. PMC 3359459 . PMID 22116390. 


Further reading[edit]

Abramson, J.J. and Abramson, Z.H. (1999). Survey Methods in Community Medicine: Epidemiological Research, Programme Evaluation, Clinical Trials (5th edition). London: Churchill Livingstone/Elsevier Health Sciences ISBN 0-443-06163-7
Adèr, H. J., Mellenbergh, G. J., and Hand, D. J. (2008). Advising on research methods: A consultant's companion. Huizen, The Netherlands: Johannes van Kessel Publishing.
Andres, Lesley (2012). "Designing and Doing Survey Research". London: Sage.
Dillman, D.A. (1978) Mail and telephone surveys: The total design method. New York: Wiley. ISBN 0-471-21555-4
Engel. U., Jann, B., Lynn, P., Scherpenzeel, A. and Sturgis, P. (2014). Improving Survey Methods: Lessons from Recent Research. New York: Routledge. ISBN 978-0-415-81762-2
Groves, R.M. (1989). Survey Errors and Survey Costs Wiley. ISBN 0-471-61171-9
Griffith, James. (2014) "Survey Research in Military Settings." in Routledge Handbook of Research Methods in Military Studies edited by Joseph Soeters, Patricia Shields and Sebastiaan Rietjens.pp. 179–193. New York: Routledge.
Leung, Wai-Ching (2001) "Conducting a Survey", in Student BMJ, (British Medical Journal, Student Edition), May 2001
Ornstein, M.D. (1998). "Survey Research." Current Sociology 46(4): iii-136.
Prince, S. a, Adamo, K. B., Hamel, M., Hardt, J., Connor Gorber, S., & Tremblay, M. (2008). A comparison of direct versus self-report measures for assessing physical activity in adults: a systematic review. International Journal of Behavioral Nutrition and Physical Activity, 5(1), 56. http://doi.org/10.1186/1479-5868-5-56
Shaughnessy, J. J., Zechmeister, E. B., & Zechmeister, J. S. (2006). Research Methods in Psychology (Seventh Edition ed.). McGraw–Hill Higher Education. ISBN 0-07-111655-9 (pp. 143–192)
Soeters, Joseph; Shields, Patricia and Rietjens, Sebastiaan.(2014). Routledge Handbook of Research Methods in Military Studies New York: Routledge.
Surveys at Curlie (based on DMOZ)








v
t
e


Social survey research



Gathering data



Collection methods
Census
Sampling for surveys
Random sampling
Questionnaire
Interview

Structured
Semi-structured
Unstructured
Couple










Analyzing data



Categorical data
Contingency table
Level of measurement
Descriptive statistics
Exploratory data analysis
Multivariate statistics
Psychometrics
Statistical inference
Statistical models

Graphical
Log-linear
Structural







Applications



Audience measurement
Demography
Market research
Opinion poll
Public opinion





Major surveys



Afrobarometer
American National Election Studies
Comparative Study of Electoral Systems
Eurobarometer
European Social Survey
European Values Study
Gallup Poll
General Social Survey
International Social Survey
Latinobarómetro
List of household surveys in the United States
National Health and Nutrition Examination Survey
New Zealand Attitudes and Values Study
World Values Survey





Associations



American Association for Public Opinion Research
European Society for Opinion and Marketing Research
International Statistical Institute
Pew Research Center
World Association for Public Opinion Research








Category
Projects

Business
Politics
Psychology
Sociology
Statistics














v
t
e


Statistics






Outline
Index










Descriptive statistics







Continuous data




Center



Mean

arithmetic
geometric
harmonic


Median
Mode





Dispersion



Variance
Standard deviation
Coefficient of variation
Percentile
Range
Interquartile range





Shape



Central limit theorem
Moments

Skewness
Kurtosis
L-moments










Count data



Index of dispersion





Summary tables



Grouped data
Frequency distribution
Contingency table





Dependence



Pearson product-moment correlation
Rank correlation

Spearman's rho
Kendall's tau


Partial correlation
Scatter plot





Graphics



Bar chart
Biplot
Box plot
Control chart
Correlogram
Fan chart
Forest plot
Histogram
Pie chart
Q–Q plot
Run chart
Scatter plot
Stem-and-leaf display
Radar chart
















Data collection







Study design



Population
Statistic
Effect size
Statistical power
Sample size determination
Missing data





Survey methodology



Sampling

stratified
cluster


Standard error
Opinion poll
Questionnaire





Controlled experiments



Design

control
optimal


Controlled trial
Randomized
Random assignment
Replication
Blocking
Interaction
Factorial experiment





Uncontrolled studies



Observational study
Natural experiment
Quasi-experiment
















Statistical inference







Statistical theory



Population
Statistic
Probability distribution
Sampling distribution

Order statistic


Empirical distribution

Density estimation


Statistical model

Lp space


Parameter

location
scale
shape


Parametric family

Likelihood (monotone)
Location–scale family
Exponential family


Completeness
Sufficiency
Statistical functional

Bootstrap
U
V


Optimal decision

loss function


Efficiency
Statistical distance

divergence


Asymptotics
Robustness





Frequentist inference




Point estimation



Estimating equations

Maximum likelihood
Method of moments
M-estimator
Minimum distance


Unbiased estimators

Mean-unbiased minimum-variance

Rao–Blackwellization
Lehmann–Scheffé theorem


Median unbiased


Plug-in





Interval estimation



Confidence interval
Pivot
Likelihood interval
Prediction interval
Tolerance interval
Resampling

Bootstrap
Jackknife







Testing hypotheses



1- & 2-tails
Power

Uniformly most powerful test


Permutation test

Randomization test


Multiple comparisons





Parametric tests



Likelihood-ratio
Wald
Score








Specific tests







Z (normal)
Student's t-test
F





Goodness of fit



Chi-squared
Kolmogorov–Smirnov
Anderson–Darling
Lilliefors
Jarque–Bera
Normality (Shapiro–Wilk)
Likelihood-ratio test
Model selection

Cross validation
AIC
BIC







Rank statistics



Sign

Sample median


Signed rank (Wilcoxon)

Hodges–Lehmann estimator


Rank sum (Mann–Whitney)
Nonparametric anova

1-way (Kruskal–Wallis)
2-way (Friedman)
Ordered alternative (Jonckheere–Terpstra)










Bayesian inference



Bayesian probability

prior
posterior


Credible interval
Bayes factor
Bayesian estimator

Maximum posterior estimator





















Correlation
Regression analysis










Correlation



Pearson product-moment
Partial correlation
Confounding variable
Coefficient of determination





Regression analysis



Errors and residuals
Regression model validation
Mixed effects models
Simultaneous equations models
Multivariate adaptive regression splines (MARS)





Linear regression



Simple linear regression
Ordinary least squares
General linear model
Bayesian regression





Non-standard predictors



Nonlinear regression
Nonparametric
Semiparametric
Isotonic
Robust
Heteroscedasticity
Homoscedasticity





Generalized linear model



Exponential families
Logistic (Bernoulli) / Binomial / Poisson regressions





Partition of variance



Analysis of variance (ANOVA, anova)
Analysis of covariance
Multivariate ANOVA
Degrees of freedom
















Categorical / Multivariate / Time-series / Survival analysis







Categorical



Cohen's kappa
Contingency table
Graphical model
Log-linear model
McNemar's test





Multivariate



Regression
Manova
Principal components
Canonical correlation
Discriminant analysis
Cluster analysis
Classification
Structural equation model

Factor analysis


Multivariate distributions

Elliptical distributions

Normal









Time-series




General



Decomposition
Trend
Stationarity
Seasonal adjustment
Exponential smoothing
Cointegration
Structural break
Granger causality





Specific tests



Dickey–Fuller
Johansen
Q-statistic (Ljung–Box)
Durbin–Watson
Breusch–Godfrey





Time domain



Autocorrelation (ACF)

partial (PACF)


Cross-correlation (XCF)
ARMA model
ARIMA model (Box–Jenkins)
Autoregressive conditional heteroskedasticity (ARCH)
Vector autoregression (VAR)





Frequency domain



Spectral density estimation
Fourier analysis
Wavelet








Survival




Survival function



Kaplan–Meier estimator (product limit)
Proportional hazards models
Accelerated failure time (AFT) model
First hitting time





Hazard function



Nelson–Aalen estimator





Test



Log-rank test



















Applications







Biostatistics



Bioinformatics
Clinical trials / studies
Epidemiology
Medical statistics





Engineering statistics



Chemometrics
Methods engineering
Probabilistic design
Process / quality control
Reliability
System identification





Social statistics



Actuarial science
Census
Crime statistics
Demography
Econometrics
National accounts
Official statistics
Population statistics
Psychometrics





Spatial statistics



Cartography
Environmental statistics
Geographic information system
Geostatistics
Kriging














Category
Portal
Commons
 WikiProject












v
t
e


Qualitative forecasting methods






Executive opinions
Delphi method
Sales force polling
Consumer surveys











						Retrieved from "https://en.wikipedia.org/w/index.php?title=Survey_methodology&oldid=814327402"					Categories: ForecastingStatistical forecastingSupply chain analyticsSupply chain management termsTime seriesSurvey methodologyPsychometricsQuantitative researchProduct testingHidden categories: Articles with DMOZ links