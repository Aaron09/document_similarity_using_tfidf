





suggested partial likelihood methods panel data merged article discuss proposed since october 2017



article statistical techniques computer data storage partial response maximum likelihood






article includes list references sources remain unclear insufficient inline citations please help improve article introducing precise citations september 2009 learn remove template message



statistics maximum likelihood estimation method estimating parameters statistical model given observations finding parameter values maximize likelihood making observations given parameters seen special case maximum posteriori estimation assumes uniform prior distribution parameters variant ignores prior therefore unregularized
method maximum likelihood corresponds many wellknown estimation methods statistics example interested heights adult female penguins unable measure height every single penguin population cost time constraints assuming heights normally distributed unknown mean variance mean variance estimated knowing heights sample overall population would accomplish taking mean variance parameters finding particular parametric values make observed results probable given model
general fixed data underlying statistical model method maximum likelihood selects values model parameters maximizes likelihood function intuitively maximizes agreement selected model observed data discrete random variables indeed maximizes probability observed data resulting distribution maximum likelihood estimation gives unified approach estimation welldefined case normal distribution many problems



contents


principles
properties

consistency
asymptotic normality

estimate boundary
data boundary parameterdependent
nuisance parameters
increasing information

2241 sketch proof




functional invariance
higherorder properties


examples

discrete uniform distribution
discrete distribution finite parameter space
discrete distribution continuous parameter space
continuous distribution continuous parameter space


nonindependent variables
iterative procedures
applications
history
also
references
reading
external links



principlesedit
main article likelihood principle
suppose sample independent identically distributed observations coming distribution unknown probability density function however surmised function belongs certain family distributions vector parameters family called parametric model value unknown referred true value parameter vector desirable find estimator















displaystyle scriptstyle theta

would close true value possible either observed variables parameter vectors
method maximum likelihood first specifies joint density function observations independent identically distributed sample joint density function









































































displaystyle fx1x2ldots xnmid theta fx1mid theta times fx2mid theta times cdots times fxnmid theta



look function different perspective considering observed values fixed parameters function whereas functions variable allowed vary freely function called likelihood





















































































displaystyle mathcal ltheta x1ldots xnfx1x2ldots xnmid theta prod i1nfximid theta



note






displaystyle

denotes separation categories input arguments parameters






displaystyle theta

observations




















displaystyle x1ldots


practice often convenient working natural logarithm likelihood function called loglikelihood





























































displaystyle mathcal ltheta x1ldots xnsum i1nln fximid theta



average loglikelihood






























displaystyle frac 1nln mathcal



indicates akin estimator indeed















displaystyle scriptstyle

estimates expected loglikelihood single observation model
method maximum likelihood estimates finding value maximizes


















displaystyle theta

method estimation defines maximum likelihood estimator














































































displaystyle theta mathrm subseteq underset theta theta operatorname argmax theta x1ldots



maximum exists estimate regardless whether maximize likelihood loglikelihood function since monotonically increasing function
many models maximum likelihood estimator found explicit function observed data many models however closedform solution maximization problem known available found numerically using optimization methods problems multiple estimates maximize likelihood problems maximum likelihood estimate exists either loglikelihood function increases without ever reaching supremum value supremum exist outside bounds






displaystyle theta

acceptable parameter values
exposition assumed data independent identically distributed method applied however broader setting long possible write joint density function parameter finite dimension depend sample size simpler extension allowance made data heterogeneity joint density equal f1x1 f2x2θ fnxn another assuming observation comes random variable distribution function complicated case time series models independence assumption dropped well
maximum likelihood estimator coincides probable bayesian estimator given uniform prior distribution parameters indeed maximum posteriori estimate parameter maximizes probability given data given bayes theorem



































































































displaystyle ptheta x1x2ldots xnfrac fx1x2ldots xnmid theta ptheta px1x2ldots













displaystyle ptheta

prior distribution parameter






























displaystyle px1x2ldots

probability data averaged parameters since denominator independent bayesian estimator obtained maximizing




































displaystyle fx1x2ldots xnmid theta ptheta

respect assume prior









displaystyle ptheta

uniform distribution bayesian estimator obtained maximizing likelihood function
































displaystyle fx1x2ldots xnmid theta

thus bayesian estimator coincides maximum likelihood estimator uniform prior distribution









displaystyle ptheta


propertiesedit
maximum likelihood estimator extremum estimator obtained maximizing function objective function loss function






















































displaystyle theta xfrac 1nsum i1nln fximid theta



sample analogue expected loglikelihood





























displaystyle theta operatorname fximid theta

expectation taken respect true density
















displaystyle fcdot theta


maximumlikelihood estimators optimum properties finite samples sense evaluated finite samples estimators greater concentration around true parametervalue1 however like estimation methods maximum likelihood estimation possesses number attractive limiting properties sample size increases infinity sequences maximum likelihood estimators properties

consistency sequence mles converges probability value estimated
asymptotic normality sample size increases distribution tends gaussian distribution mean






displaystyle theta

covariance matrix equal inverse fisher information matrix
efficiency achieves cramér–rao lower bound sample size tends infinity means consistent estimator lower asymptotic mean squared error estimators attaining bound
secondorder efficiency correction bias

consistencyedit
conditions outlined maximum likelihood estimator consistent consistency means sufficiently large number observations possible find value arbitrary precision mathematical terms means goes infinity estimator















displaystyle scriptstyle theta

converges probability true value

































































displaystyle beginmatrixhat theta mathrm xrightarrow theta 0endmatrix































slightly stronger conditions estimator converges almost surely strongly

































































displaystyle beginmatrixhat theta mathrm xrightarrow textas theta 0endmatrix































establish consistency following conditions sufficient2


identification model





































displaystyle theta theta 0quad leftrightarrow quad fcdot theta fcdot theta



words different parameter values correspond different distributions within model condition hold would value generate identical distribution observable data would able distinguish parameters even infinite amount data—these parameters would observationally equivalent
identification condition absolutely necessary estimator consistent condition holds limiting likelihood function unique global maximum
compactness parameter space model compact

identification condition establishes loglikelihood unique global maximum compactness implies likelihood cannot approach maximum value arbitrarily close point demonstrated example picture right
compactness sufficient condition necessary condition compactness replaced conditions


concavity loglikelihood function compactness nonempty upper level sets loglikelihood function
existence compact neighborhood outside loglikelihood function less maximum least



continuity function continuous almost values













































displaystyle fxmid theta mathbb 0theta



continuity replaced slightly weaker condition upper semicontinuity
dominance exists integrable respect distribution fxθ0






































displaystyle fxmid theta dxquad text theta theta



uniform large numbers dominance condition together continuity establish uniform convergence probability loglikelihood























































displaystyle theta theta theta xell theta xrightarrow






dominance condition employed case observations noniid case uniform convergence probability checked showing sequence




















displaystyle scriptstyle theta

stochastically equicontinuous
wants demonstrate estimator















displaystyle scriptstyle theta

converges almost surely stronger condition uniform convergence almost surely imposed
























































displaystyle theta theta xmid theta theta xrightarrow textas



asymptotic normalityedit






section require cleanup meet wikipedias quality standards cleanup reason specified please help improve section january 2010 learn remove template message



wide range situations maximum likelihood parameter estimates exhibit asymptotic normality equal true parameters plus random error approximately normal given sufficient data errors variance decays property hold necessary estimator suffer following issues
estimate boundaryedit
sometimes maximum likelihood estimate lies boundary possible parameters boundary strictly speaking allowed likelihood gets larger larger parameter approaches boundary standard asymptotic theory needs assumption true parameter value lies away boundary enough data maximum likelihood estimate keep away boundary smaller samples estimate boundary cases asymptotic theory clearly give practically useful approximation examples would variancecomponent models component variance must satisfy constraint
data boundary parameterdependentedit
theory apply simple data values positive probability positive probability density depend unknown parameter simple example parameterdependence hold case estimating independent identically distributed observations common distribution uniform range estimation purposes relevant range cannot less largest observation interval compact exists maximum likelihood function estimate theta exists greater estimate also greater likelihood contrast interval includes endpoint compact case maximum likelihood estimator exists however case maximum likelihood estimator biased asymptotically maximum likelihood estimator normally distributed3
nuisance parametersedit
maximum likelihood estimations model number nuisance parameters asymptotic behaviour outlined hold number nuisance parameters increase number observations sample size wellknown example case observations occur pairs observations pair different unknown mean otherwise observations independent normally distributed common variance observations parameters well known maximum likelihood estimate variance converge true value variance
increasing informationedit
asymptotics hold cases assumption independent identically distributed observations hold basic requirement amount information data increases indefinitely sample size increases requirement either much dependence data example observations essentially identical existing observations independent observations subject increasing observation error
regularity conditions ensure behavior

first second derivatives loglikelihood function exist “well defined”
fisher information matrix nonsingular
fisher information matrix continuous function parameters
maximum likelihood estimator consistent

suppose conditions consistency maximum likelihood estimator satisfied and4

interiorθ
twice continuously differentiable neighborhood
supθ∈n∇θfx supθ∈n∇θθfx
e∇θln ∇θln exists nonsingular
esupθ∈n∇θθln

maximum likelihood estimator asymptotically normal distribution










































































displaystyle sqrt nbig theta mathrm theta 0big xrightarrow mathcal n0i1



sketch proofedit
since loglikelihood function differentiable











displaystyle theta

lies interior parameter






displaystyle theta

maximum firstorder condition satisfied


















































































displaystyle nabla theta theta xfrac 1nsum i1nnabla theta fximid theta



loglikelihood twice differentiable expression expanded taylor series around point













displaystyle theta theta

































































































































displaystyle 0frac 1nsum i1nnabla theta fximid theta 0bigg frac 1nsum i1nnabla theta theta fximid tilde theta bigg theta theta

















displaystyle tilde theta

point intermediate











displaystyle theta















displaystyle theta

expression derive












































































































































displaystyle sqrt nhat theta theta 0bigg frac 1nsum i1nnabla theta theta fximid tilde theta bigg 1frac 1sqrt nsum i1nnabla theta fximid theta



expression square brackets converges probability





































displaystyle hmathbb leftnabla theta theta fxtheta 0right

large numbers continuous mapping theorem ensures inverse expression also converges probability












displaystyle

second central limit theorem converges distribution multivariate normal mean zero variance matrix equal fisher information






displaystyle

thus applying slutskys theorem whole expression obtain











































































displaystyle sqrt nhat theta theta xrightarrow mathcal nbig h1ih1big



finally information equality guarantees model correctly specified matrix






displaystyle

equal fisher information






displaystyle

variance expression simplifies












displaystyle


functional invarianceedit
maximum likelihood estimator selects parameter value gives observed data largest possible probability probability density continuous case parameter consists number components define separate maximum likelihood estimators corresponding component complete parameter consistent













displaystyle widehat theta

transformation definition































displaystyle widehat alpha gwidehat theta



maximizes socalled profile likelihood






































displaystyle lalpha theta alpha gtheta ltheta



also invariant respect certain transformations data depend parameters estimated density functions satisfy















































displaystyle fyyfrac fxxgx



hence likelihood functions differ factor depend model parameters
example parameters lognormal distribution normal distribution fitted logarithm data
higherorder propertiesedit
standard asymptotics tells maximum likelihood estimator √nconsistent asymptotically efficient meaning reaches cramér–rao bound
































































displaystyle sqrt nhat theta textmletheta xrightarrow mathcal



fisher information matrix
























































































displaystyle ijkoperatorname xbigg frac partial ftheta 0xtpartial theta jpartial theta kbigg



particular means bias maximum likelihood estimator equal zero order n−12 however consider higherorder terms expansion distribution estimator turns θmle bias order bias equal componentwise5











































































































displaystyle bsequiv operatorname theta mathrm theta 0sfrac 1ncdot isiijkbig tfrac 12kijkjjikbig



einsteins summation convention repeating indices adopted denotes jkth component inverse fisher information matrix














































































































































































































displaystyle tfrac 12kijkjjikoperatorname xbigg frac 12frac partial ftheta 0xtpartial theta ipartial theta jpartial theta kfrac partial ftheta 0xtpartial theta jfrac partial ftheta 0xtpartial theta ipartial theta kbigg



using formulas possible estimate secondorder bias maximum likelihood estimator correct bias subtracting























































displaystyle theta mathrm theta mathrm



estimator unbiased terms order called biascorrected maximum likelihood estimator
biascorrected estimator secondorder efficient least within curved exponential family meaning minimal mean squared error among secondorder biascorrected estimators terms order possible continue process derive thirdorder biascorrection term however shown kano 1996 maximum likelihood estimator thirdorder efficient
examplesedit






suggested maximum likelihood estimation flow data merged article discuss proposed since october 2017



discrete uniform distributionedit
main article german tank problem
consider case tickets numbered placed selected random uniform distribution thus sample size unknown maximum likelihood estimator













displaystyle

number drawn ticket likelihood greatest note maximum likelihood estimate occurs lower extreme possible values rather somewhere middle range possible values would result less bias expected value number drawn ticket therefore expected value













displaystyle

result sample size maximum likelihood estimator systematically underestimate
discrete distribution finite parameter spaceedit
suppose wishes determine biased unfair coin call probability tossing head goal becomes determine
suppose coin tossed times sample might something like count number heads observed
probability tossing tails suppose outcome heads tails suppose coin taken containing three coins gives heads probability gives heads probability another gives heads probability coins lost labels unknown using maximum likelihood estimation coin largest likelihood found given data observed using probability mass function binomial distribution sample size equal number successes equal different values probability success likelihood function defined takes three values






































































0000


































































0012


































































0054






displaystyle beginalignedprmathrm 49mid p13binom 8049134911331approx 00006ptprmathrm 49mid p12binom 8049124911231approx 00126ptprmathrm 49mid p23binom 8049234912331approx 0054endaligned



likelihood maximized maximum likelihood estimate
discrete distribution continuous parameter spaceedit
suppose coin could value likelihood function maximised



























































displaystyle lpfdmathrm 49mid pbinom 8049p491p31



maximisation possible values




likelihood function proportion value binomial process


maximize function differentiating respect setting zero



























































































































































































displaystyle beginaligned0frac partial partial pleftbinom 8049p491p31right8pt049p481p3131p491p308ptp481p30left491p31pright8ptp481p30left4980prightendaligned



solutions 4980 solution maximizes likelihood clearly 4980 since result likelihood zero thus maximum likelihood estimator 4980
result easily generalized substituting letter place represent observed number successes bernoulli trials letter place represent number bernoulli trials exactly calculation yields maximum likelihood estimator sequence bernoulli trials resulting successes
continuous distribution continuous parameter spaceedit
normal distribution




















displaystyle mathcal sigma

probability density function












































































displaystyle fxmid sigma 2frac 1sqrt sigma leftfrac 22sigma 2right



corresponding probability density function sample independent identically distributed normal random variables likelihood














































































































































displaystyle fx1ldots xnmid sigma 2prod i1nfximid sigma 2leftfrac 12pi sigma 2rightn2exp leftfrac i1nximu 22sigma 2right



conveniently










































































































































displaystyle fx1ldots xnmid sigma 2leftfrac 12pi sigma 2rightn2exp leftfrac i1nxibar x2nbar 22sigma 2right

















displaystyle

sample mean
family distributions parameters maximize likelihood






































displaystyle mathcal sigma fx1ldots xnmid sigma

parameters simultaneously possible individually
since logarithm function continuous strictly increasing function range likelihood values maximize likelihood also maximize logarithm likelihoods logarithm strictly increasing likelihood written follows



















































































displaystyle logmathcal sigma n2log2pi sigma 2frac 12sigma 2sum i1nximu



note loglikelihood closely related information entropy fisher information
compute derivatives likelihood follows













































































displaystyle beginaligned0frac partial partial logmathcal sigma 0frac 2nbar 2sigma 2endaligned



solved
















































displaystyle xsum i1nfrac



indeed maximum function since turning point second derivative strictly less zero expectation value equal parameter given distribution
























displaystyle eleftwidehat rightmu



means maximum likelihood estimator













displaystyle widehat

unbiased
similarly differentiate likelihood respect equate zero











































































































































































































































































































































displaystyle beginaligned0frac partial partial sigma leftleftfrac 12pi sigma 2rightn2exp leftfrac i1nxibar x2nbar 22sigma 2rightright6ptfrac partial partial sigma leftfrac n2log leftfrac 12pi sigma 2rightfrac i1nxibar x2nbar 22sigma 2right6ptfrac nsigma frac i1nxibar x2nbar 2sigma 3endaligned



solved






















































displaystyle widehat sigma 2frac 1nsum i1nximu



inserting estimate















displaystyle widehat

obtain






































































































































displaystyle widehat sigma 2frac 1nsum i1nxibar x2frac 1nsum i1nxi2frac 1n2sum i1nsum j1nxixj



calculate expected value convenient rewrite expression terms zeromean random variables statistical error




















displaystyle delta iequiv

expressing estimate variables yields












































































































displaystyle widehat sigma 2frac 1nsum i1nmu delta i2frac 1n2sum i1nsum j1nmu delta delta



simplifying expression utilizing facts


















displaystyle eleftdelta iright0


























displaystyle edelta i2sigma

allows obtain











































displaystyle eleftwidehat sigma 2rightfrac n1nsigma



means estimator













displaystyle widehat sigma

biased however













displaystyle widehat sigma

consistent
formally maximum likelihood estimator

















displaystyle theta sigma













































displaystyle widehat theta leftwidehat widehat sigma 2right



case mles could obtained individually general case mles would obtained simultaneously
normal likelihood maximum takes particularly simple form




































































displaystyle logmathcal lhat sigma frac n2log2pi sigma



maximum likelihood shown general least squares even nonlinear least squares often used determining likelihoodbased approximate confidence intervals confidence regions generally accurate using asymptotic normality discussed
nonindependent variablesedit
case variables correlated independent random variables independent joint probability density function product individual probability density functions























displaystyle fxyfxfy



suppose constructs ordern gaussian vector random variables























displaystyle x1ldots

variable means given























displaystyle 1ldots

furthermore covariance matrix denoted






displaystyle sigma


joint probability density function random variables given



















































































































































displaystyle fx1ldots xnfrac 12pi n2sqrt textdetsigma leftfrac 12leftx1mu 1ldots xnmu nrightsigma 1leftx1mu 1ldots xnmu nrighttright



variable case joint probability density function given




















































































































































































displaystyle fxyfrac 12pi sigma xsigma ysqrt 1rho 2exp leftfrac 121rho 2leftfrac x2sigma x2frac 2rho xymu ysigma xsigma yfrac y2sigma y2rightright



cases joint density function exists likelihood function defined section principles using density
iterative proceduresedit
consider problems states











displaystyle

parameters











displaystyle sigma

require estimated iterative procedures expectationmaximization algorithms used solve joint stateparameter estimation problems
example suppose samples state estimates


















displaystyle

together sample mean













displaystyle

calculated either minimumvariance kalman filter minimumvariance smoother using previous variance estimate


















displaystyle widehat sigma

next variance iterate obtained maximum likelihood estimate calculation




































































displaystyle widehat sigma 2frac 1nsum i1nhat xibar



convergence mles within filtering smoothing algorithms studied literature678
applicationsedit
maximum likelihood estimation used wide range statistical models including

linear models generalized linear models
exploratory confirmatory factor analysis
structural equation modeling
many situations context hypothesis testing confidence intervals
discrete choice models
signal detection filtering

uses arise across applications widespread fields including

communication systems
psychometrics
econometrics
timedelay arrival tdoa acoustic electromagnetic detection
data modeling nuclear particle physics
magnetic resonance imaging910
computational phylogenetics
origindestination pathchoice modeling transport networks
geographical satelliteimage classification
power system state estimation

historyedit




ronald fisher 1913


maximumlikelihood estimation recommended analyzed fruitless attempts proofs widely popularized ronald fisher 1912 192211 although used earlier carl friedrich gauss pierresimon laplace thorvald thiele francis ysidro edgeworth12
maximumlikelihood estimation finally transcended heuristic justification proof published samuel wilks 1938 called wilks theorem13 theorem shows error logarithm likelihood values estimates multiple independent samples distributed enables determination confidence region around estimate parameters difficult part proof depends expected value fisher information matrix provided theorem fisher14 wilks continued improve generality theorem throughout life general proof published 196215
theory behind maximum likelihood estimation developed bayesian statistics11
reviews development maximum likelihood estimation provided number authors16
alsoedit


statistics portal



estimation methods

generalized method moments methods related likelihood equation maximum likelihood estimation
mestimator approach used robust statistics
maximum posteriori estimator contrast calculate estimators prior knowledge postulated
maximum spacing estimation related method robust many situations
maximum entropy estimation
method moments statistics another popular method finding parameters distributions
method support variation maximum likelihood technique
minimum distance estimation
quasimaximum likelihood estimator estimator misspecified still consistent
restricted maximum likelihood variation using likelihood function calculated transformed data


related concepts

bhhh algorithm nonlinear optimization algorithm popular maximum likelihood estimations
extremum estimator general class estimators belongs
fisher information information matrix relationship covariance matrix estimates
likelihood function description likelihood functions
mean squared error measure good estimator distributional parameter maximum likelihood estimator estimator
ransac method estimate parameters mathematical model given data contains outliers
rao–blackwell theorem result yields process finding best possible unbiased estimator sense minimal mean squared error often good starting place process
sufficient statistic function data exists unique depend data
wilks’ theorem provides means estimating size shape region roughly equallyprobable estimates populations parameter values using information single sample using chisquared distribution



referencesedit


pfanzagl 1994
newey mcfadden 1994 theorem
lehmann casella 1998
newey mcfadden 1994 theorem
snell 1968 formula
einicke malos reid hainsworth january 2009 riccati equation algorithm convergence inertial navigation alignment ieee trans signal processing 370–375 doi101109tsp20082007090
einicke falco malos 2010 algorithm state matrix estimation navigation ieee signal processing letters 437–440 doi101109lsp20102043151
einicke falco dunn reid 2012 iterative smootherbased variance estimation ieee signal processing letters 275–278 doi101109lsp20122190278
sijbers dekker 2004 maximum likelihood estimation signal amplitude noise variance data magnetic resonance medicine 586–594 doi101002mrm10728 pmid 15004801
sijbers dekker scheunders dyck 1998 maximum likelihood estimation rician distribution parameters ieee transactions medical imaging 357–361 doi10110942712125 pmid 9735899
pfanzagl johann assistance hamböker 1994 parametric statistical theory walter gruyter berlin 207–208 isbn 3110138638 maint multiple names authors list link
edgeworth september 1908 edgeworth december 1908
wilks 1938 largesample distribution likelihood ratio testing composite hypotheses annals mathematical statistics 60–62 doi101214aoms1177732360
owen 2001 empirical likelihood london chapman hallboca raton press isbn 9781584880714
wilks samuel 1962 mathematical statistics york john wiley sons isbn 9780471946502
savage 1976 pratt 1976 stigler 1978 1986 1999 hald 1998 1999 aldrich 1997


readingedit


aldrich john 1997 fisher making maximum likelihood 1912–1922 statistical science 162–176 doi101214ss1030037906 1617519
andersen erling 1970 asymptotic properties conditional maximum likelihood estimators journal royal statistical society 283–301
andersen erling 1980 discrete statistical models social science applications north holland 1980
basu debabrata 1988 statistical information likelihood collection critical essays basu ghosh jayanta editor lecture notes statistics volume springerverlag 1988
david snell joyce 1968 general definition residuals journal royal statistical society series 248–275 jstor 2984505
edgeworth francis 1908 probable errors frequencyconstants journal royal statistical society 499–512 doi1023072339293 jstor 2339293
edgeworth francis 1908 probable errors frequencyconstants journal royal statistical society 651–678 doi1023072339378 jstor 2339378
einicke 2012 smoothing filtering prediction estimating past present future rijeka croatia intech isbn 9789533077529
ferguson thomas 1982 inconsistent maximum likelihood estimate journal american statistical association 831–834 doi10108001621459198210477894 jstor 2287314
ferguson thomas 1996 course large sample theory chapman hall isbn 0412043718
hald anders 1998 history mathematical statistics 1750 1930 york wiley isbn 0471179124
hald anders 1999 history maximum likelihood relation inverse probability least squares statistical science 214–222 doi101214ss1009212248 jstor 2676741
kano yutaka 1996 thirdorder efficiency implies fourthorder efficiency journal japan statistical society 101–117 doi1014490jjss199526101
lucien 1990 maximum likelihood introduction review 153–171 doi1023071403464
lucien yang grace 2000 asymptotics statistics basic concepts second springer isbn 0387950362
lucien 1986 asymptotic methods statistical decision theory springerverlag isbn 0387963073
lehmann erich casella george 1998 theory point estimation springer isbn 0387985026
newey whitney mcfadden daniel 1994 chapter large sample estimation hypothesis testing engle robert mcfadden handbook econometrics vol4 elsevier science 2111–2245 isbn 0444887660
pratt john 1976 edgeworth fisher efficiency maximum likelihood estimation annals statistics 501–514 doi101214aos1176343457 jstor 2958222
ruppert david 2010 statistics data analysis financial engineering springer isbn 9781441977861
savage leonard 1976 rereading fisher annals statistics 441–500 doi101214aos1176343456 jstor 2958221
stigler stephen 1978 francis ysidro edgeworth statistician journal royal statistical society series 287–322 doi1023072344804 jstor 2344804
stigler stephen 1986 history statistics measurement uncertainty 1900 harvard university press isbn 0674403401
stigler stephen 1999 statistics table history statistical concepts methods harvard university press isbn 0674836014
vaart 1998 asymptotic statistics isbn 0521784506


external linksedit

hazewinkel michiel 2001 1994 maximumlikelihood method encyclopedia mathematics springer sciencebusiness media kluwer academic publishers isbn 9781556080104
lemke 2016 maximum likelihood estimation fixed point ideals binary tensors francisco state university masters theses collection degree mathematics francisco francisco state university

oclc 980058195 httphdlhandlenet102113173201

maximum likelihood estimation primer excellent tutorial
implementing likelihood function using
selection likelihood functions
tutorial maximum likelihood estimation journal mathematical psychology citeseerx 101174671












statistics






outline
index










descriptive statistics







continuous data




center



mean

arithmetic
geometric
harmonic


median
mode





dispersion



variance
standard deviation
coefficient variation
percentile
range
interquartile range





shape



central limit theorem
moments

skewness
kurtosis
lmoments










count data



index dispersion





summary tables



grouped data
frequency distribution
contingency table





dependence



pearson productmoment correlation
rank correlation

spearmans
kendalls


partial correlation
scatter plot





graphics



chart
biplot
plot
control chart
correlogram
chart
forest plot
histogram
chart
plot
chart
scatter plot
stemandleaf display
radar chart
















data collection







study design



population
statistic
effect size
statistical power
sample size determination
missing data





survey methodology



sampling

stratified
cluster


standard error
opinion poll
questionnaire





controlled experiments



design

control
optimal


controlled trial
randomized
random assignment
replication
blocking
interaction
factorial experiment





uncontrolled studies



observational study
natural experiment
quasiexperiment
















statistical inference







statistical theory



population
statistic
probability distribution
sampling distribution

order statistic


empirical distribution

density estimation


statistical model

space


parameter

location
scale
shape


parametric family

likelihood monotone
location–scale family
exponential family


completeness
sufficiency
statistical functional

bootstrap




optimal decision

loss function


efficiency
statistical distance

divergence


asymptotics
robustness





frequentist inference




point estimation



estimating equations

maximum likelihood
method moments
mestimator
minimum distance


unbiased estimators

meanunbiased minimumvariance

rao–blackwellization
lehmann–scheffé theorem


median unbiased


plugin





interval estimation



confidence interval
pivot
likelihood interval
prediction interval
tolerance interval
resampling

bootstrap
jackknife







testing hypotheses



2tails
power

uniformly powerful test


permutation test

randomization test


multiple comparisons





parametric tests



likelihoodratio
wald
score








specific tests







normal
students ttest






goodness



chisquared
kolmogorov–smirnov
anderson–darling
lilliefors
jarque–bera
normality shapiro–wilk
likelihoodratio test
model selection

cross validation









rank statistics



sign

sample median


signed rank wilcoxon

hodges–lehmann estimator


rank mann–whitney
nonparametric anova

1way kruskal–wallis
2way friedman
ordered alternative jonckheere–terpstra










bayesian inference



bayesian probability

prior
posterior


credible interval
bayes factor
bayesian estimator

maximum posterior estimator





















correlation
regression analysis










correlation



pearson productmoment
partial correlation
confounding variable
coefficient determination





regression analysis



errors residuals
regression model validation
mixed effects models
simultaneous equations models
multivariate adaptive regression splines mars





linear regression



simple linear regression
ordinary least squares
general linear model
bayesian regression





nonstandard predictors



nonlinear regression
nonparametric
semiparametric
isotonic
robust
heteroscedasticity
homoscedasticity





generalized linear model



exponential families
logistic bernoulli binomial poisson regressions





partition variance



analysis variance anova anova
analysis covariance
multivariate anova
degrees freedom
















categorical multivariate timeseries survival analysis







categorical



cohens kappa
contingency table
graphical model
loglinear model
mcnemars test





multivariate



regression
manova
principal components
canonical correlation
discriminant analysis
cluster analysis
classification
structural equation model

factor analysis


multivariate distributions

elliptical distributions

normal









timeseries




general



decomposition
trend
stationarity
seasonal adjustment
exponential smoothing
cointegration
structural break
granger causality





specific tests



dickey–fuller
johansen
qstatistic ljung–box
durbin–watson
breusch–godfrey





time domain



autocorrelation

partial pacf


crosscorrelation
arma model
arima model box–jenkins
autoregressive conditional heteroskedasticity arch
vector autoregression





frequency domain



spectral density estimation
fourier analysis
wavelet








survival




survival function



kaplan–meier estimator product limit
proportional hazards models
accelerated failure time model
first hitting time





hazard function



nelson–aalen estimator





test



logrank test



















applications







biostatistics



bioinformatics
clinical trials studies
epidemiology
medical statistics





engineering statistics



chemometrics
methods engineering
probabilistic design
process quality control
reliability
system identification





social statistics



actuarial science
census
crime statistics
demography
econometrics
national accounts
official statistics
population statistics
psychometrics





spatial statistics



cartography
environmental statistics
geographic information system
geostatistics
kriging














category
portal
commons
wikiproject











retrieved httpsenwikipediaorgwindexphptitlemaximumlikelihoodestimationoldid806790525 categories maximum likelihood estimationmestimatorsprobability distribution fittinghidden categories maint multiple names authors listarticles merged october 2017all articles mergedarticles lacking intext citations september 2009all articles lacking intext citationsarticles needing cleanup january 2010all pages needing cleanupcleanup tagged articles without reason field january 2010wikipedia pages needing cleanup january 2010
